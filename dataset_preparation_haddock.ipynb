{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformating of haddock annotation datasets made by the passive acoustics group at NEFSC.\n",
    "\n",
    "\n",
    "## Purpose of this notebook\n",
    "This notebook describes the steps involved in cleaning up and reorganizing the haddock sound manual annotations that were used done in the passive acoustics group at NEFASC.\n",
    "\n",
    "The specific objectives of this notebook are:\n",
    "\n",
    "- Reorganize the audio data so they are sorted by deployment and locations\n",
    "- Convert the XBat annotations to Raven annotation tables.\n",
    "- Add metadata to all annotations (i.e., coordinates, depths, location, dates, etc)\n",
    "- Make annotation labels consistent (i.e. 'HK' for haddock, 'NN' for noise)\n",
    "\n",
    "\n",
    "## Description of the data and manual annotations\n",
    "\n",
    "This dataset uses manual annotations made with Xbat on data from Stellwagen Bank. Two days of data were annotated manually: 30 Oct 2010 at NOPP8 and 4 Apr 2008 at NOPP8. The first step of this analysis consisted of converting the Xbat annotations (mat files) to Raven format. This was donne with Matlab, Excel, and Raven. This stage is not documented in the notebook.\n",
    "\n",
    "Audio files originaly have 10 channels. The software Sox was used to extract the channel that was annotated as a separate file.\n",
    "\n",
    "\n",
    "## Adding annotation fields in Raven\n",
    "\n",
    "Since the times of the original annotations are relative to the first file of each subset, we need to add additional fields so we can recalculate annotation times relative to the start of each audio file. This will make the manipulation of annotations much easier and cleaner.\n",
    "\n",
    "1. Open all files from a same subset in Raven\n",
    "2. Load the annotation table\n",
    "3. Click right on the header section of the annotation table in Raven, then select \"Choose Measurements...\"\n",
    "4. Add the measurements \"File Offset (s)\", \"Begin File\", and \"Begin Path\".\n",
    "5. Save the updated annotation table (File > Save Selection Table). In the rest of this notebook this new table file is appended with \"_modified.txt\"\n",
    "\n",
    "Data and respective Raven annotations were places in the folders USA-NEFSC-SBNMS-200803-NOPP2_CH08 and USA-NEFSC-SBNMS-200910-NOPP8_CH07"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and define functions used throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ecosound.core.annotation import Annotation\n",
    "from ecosound.core.metadata import DeploymentInfo\n",
    "from ecosound.core.audiotools import Sound\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import uuid\n",
    "\n",
    "def get_datetime_from_filename(filename):\n",
    "    time_format = \"%Y%m%d_%H%M%S\"\n",
    "    file_offset_s_regex = \"_[0-9]+s\"\n",
    "    file_offset_ms_regex = \"_[0-9]+s\"\n",
    "    file_orig_regex = \"_[0-9]{8}_[0-9]{6}.\"    \n",
    "    # first part - date/time of origninal audio file\n",
    "    p1 = re.compile(file_orig_regex)\n",
    "    datestr_1 = p1.search(filename)\n",
    "    date = datetime.strptime(datestr_1[0][1:-1],time_format)    \n",
    "    ## second part - nb of seconds\n",
    "    #p1 = re.compile(file_orig_regex)\n",
    "    #datestr_1 = p1.search(df['Begin File'].iloc[0])\n",
    "    #date = datetime.strptime(datestr_1[0][1:-1],time_format)    \n",
    "    return date   \n",
    "\n",
    "def load_raven_table(root_dir,audio_dir,annotation_file,deployment_file):\n",
    "    ## load Raven annotations\n",
    "    df = pd.read_csv(os.path.join(root_dir, annotation_file), sep='\\t')\n",
    "    df = df[df['View']== 'Spectrogram 1'] # remove all \"waveform\" rows (redundant with the \"Spectrogram\" ones)\n",
    "    df = df.reset_index(drop=True)    \n",
    "    ## find out start date/time for each audio file\n",
    "    files_date=df['Begin File'].apply(get_datetime_from_filename)\n",
    "    # Definition of start and stop time offsets of annoatations (relative to start of each audio file)\n",
    "    duration = df['End Time (s)']-df['Begin Time (s)']\n",
    "    start_offset = df['File Offset (s)']\n",
    "    end_offset = start_offset + duration\n",
    "    ## Populate annotation object\n",
    "    annot = Annotation()\n",
    "    annot.data['audio_file_start_date'] = files_date\n",
    "    annot.data['audio_channel'] = df['Channel']-1\n",
    "    annot.data['audio_file_name'] = df['Begin File'].apply(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
    "    annot.data['audio_file_dir'] = audio_dir\n",
    "    annot.data['audio_file_extension'] = df['Begin Path'].apply(lambda x: os.path.splitext(x)[1])\n",
    "    annot.data['time_min_offset'] = start_offset\n",
    "    annot.data['time_max_offset'] = end_offset\n",
    "    annot.data['time_min_date'] = pd.to_datetime(annot.data['audio_file_start_date'] + pd.to_timedelta(annot.data['time_min_offset'], unit='s'))\n",
    "    annot.data['time_max_date'] = pd.to_datetime(annot.data['audio_file_start_date'] + pd.to_timedelta(annot.data['time_max_offset'], unit='s'))\n",
    "    annot.data['frequency_min'] = df['Low Freq (Hz)']\n",
    "    annot.data['frequency_max'] = df['High Freq (Hz)']    \n",
    "    annot.data['label_class'] = df['tags']\n",
    "    annot.data['from_detector'] = False\n",
    "    annot.data['software_name'] = 'raven'\n",
    "    annot.data['uuid'] = annot.data.apply(lambda _: str(uuid.uuid4()), axis=1)\n",
    "    annot.data['duration'] = annot.data['time_max_offset'] - annot.data['time_min_offset']\n",
    "    annot.insert_metadata(os.path.join(root_dir, deployment_file)) # insert metadata\n",
    "    annot.check_integrity(verbose=True, ignore_frequency_duplicates=True) # check integrity\n",
    "    print(len(annot), 'annotations imported.')\n",
    "    return annot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create deployment info files with metadata for each deployment\n",
    "\n",
    "Instantiate a DeploymentInfo object to handle metadata for the deployment, and create an empty deployment info file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "Deployment = DeploymentInfo()\n",
    "# write empty file to fill in (do once only)\n",
    "#Deployment.write_template(os.path.join(root_dir, deployment_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A csv file \"deployment_info.csv\" has now been created in the root_dir. It is empty and only has column headers, and includes teh following fiilds:\n",
    "\n",
    "* audio_channel_number\n",
    "* UTC_offset\n",
    "* sampling_frequency (in Hz)\n",
    "* bit_depth \n",
    "* mooring_platform_name\n",
    "* recorder_type\n",
    "* recorder_SN\n",
    "* hydrophone_model\n",
    "* hydrophone_SN\n",
    "* hydrophone_depth\n",
    "* location_name\n",
    "* location_lat\n",
    "* location_lon\n",
    "* location_water_depth\n",
    "* deployment_ID\n",
    "* deployment_date\n",
    "* recovery_date\n",
    "\n",
    "This file needs to be filled in by the user with the appropriate deployment information. Once filled in, the file can be loaded using the Deployment object:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning annotations\n",
    "\n",
    "Now we go through the annotations for each deployment/dataset and add the associated metadata, correct inconsistencies in annotations labels, and save as a NetCDF and Raven file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1a: USA-NEFSC-SBNMS-200803-NOPP2_CH08 - single pulses\n",
    "\n",
    "Definition of all the paths of all folders with the raw annotation and audio files for this deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'C:\\Users\\xavier.mouy\\Documents\\GitHub\\minke-whale-dataset\\datasets\\USA-NEFSC-SBNMS-200803-NOPP2_CH08'\n",
    "audio_dir = r'C:\\Users\\xavier.mouy\\Documents\\GitHub\\minke-whale-dataset\\datasets\\USA-NEFSC-SBNMS-200803-NOPP2_CH08'\n",
    "deployment_file = r'deployment_info.csv' \n",
    "annotation_file = r'NOPP2_20090404_haddock_singles_raven_table_modified.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load and format the manual annotations for this dataset and add the metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries removed: 0\n",
      "Integrity test succesfull\n",
      "182 annotations imported.\n"
     ]
    }
   ],
   "source": [
    "annot = load_raven_table(root_dir,audio_dir,annotation_file,deployment_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the different annotation labels that were used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "print(annot.get_labels_class())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's insert label \"HK\"for haddock amd \"P\" (pulse) as second label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HK']\n"
     ]
    }
   ],
   "source": [
    "annot.insert_values(label_class= 'HK')\n",
    "annot.insert_values(label_subclass= 'P')\n",
    "print(annot.get_labels_class())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, having a look a summary of all the annotations available in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_class                         HK  Total\n",
      "deployment_ID                                \n",
      "USA-NEFSC-SBNMS-200803-NOPP2_CH08  182    182\n",
      "Total                              182    182\n"
     ]
    }
   ],
   "source": [
    "# print summary (pivot table)\n",
    "print(annot.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can now be saved as a Raven annotation file and netcdf4 file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xavier.mouy\\Anaconda3\\envs\\ecosound\\lib\\site-packages\\pandas\\core\\arrays\\timedeltas.py:754: RuntimeWarning: invalid value encountered in multiply\n",
      "  return self - (self // other) * other\n"
     ]
    }
   ],
   "source": [
    "annot.to_netcdf(os.path.join(root_dir, 'Annotations_dataset_' + annot.data['deployment_ID'][0] +'_singlepulse_annotations.nc'))\n",
    "#annot.to_raven(root_dir, outfile='Annotations_dataset_' + annot.data['deployment_ID'][0] +'.Table.1.selections.txt', single_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1b:  USA-NEFSC-SBNMS-200803-NOPP2_CH08 - pulse trains\n",
    "Now we can repeat the step above for all the other datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'C:\\Users\\xavier.mouy\\Documents\\GitHub\\minke-whale-dataset\\datasets\\USA-NEFSC-SBNMS-200803-NOPP2_CH08'\n",
    "audio_dir = r'C:\\Users\\xavier.mouy\\Documents\\GitHub\\minke-whale-dataset\\datasets\\USA-NEFSC-SBNMS-200803-NOPP2_CH08'\n",
    "deployment_file = r'deployment_info.csv' \n",
    "annotation_file = r'NOPP2_20080404_haddock_pulsetrains_concatenated_raven_table_modified.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries removed: 0\n",
      "Integrity test succesfull\n",
      "2753 annotations imported.\n"
     ]
    }
   ],
   "source": [
    "annot = load_raven_table(root_dir,audio_dir,annotation_file,deployment_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "print(annot.get_labels_class())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_class                          HK  Total\n",
      "deployment_ID                                 \n",
      "USA-NEFSC-SBNMS-200803-NOPP2_CH08  2753   2753\n",
      "Total                              2753   2753\n"
     ]
    }
   ],
   "source": [
    "annot.insert_values(label_class= 'HK')\n",
    "annot.insert_values(label_subclass= 'PT')\n",
    "print(annot.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xavier.mouy\\Anaconda3\\envs\\ecosound\\lib\\site-packages\\pandas\\core\\arrays\\timedeltas.py:754: RuntimeWarning: invalid value encountered in multiply\n",
      "  return self - (self // other) * other\n"
     ]
    }
   ],
   "source": [
    "annot.to_netcdf(os.path.join(root_dir, 'Annotations_dataset_' + annot.data['deployment_ID'][0] +'_pulsetrain_annotations.nc'))\n",
    "#annot.to_raven(root_dir, outfile='Annotations_dataset_' + annot.data['deployment_ID'][0] +'.Table.1.selections.txt', single_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2a: USA-NEFSC-SBNMS-200910-NOPP8_CH07 - single pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'C:\\Users\\xavier.mouy\\Documents\\GitHub\\minke-whale-dataset\\datasets\\USA-NEFSC-SBNMS-200910-NOPP8_CH07'\n",
    "audio_dir = r'C:\\Users\\xavier.mouy\\Documents\\GitHub\\minke-whale-dataset\\datasets\\USA-NEFSC-SBNMS-200910-NOPP8_CH07'\n",
    "deployment_file = r'deployment_info.csv' \n",
    "annotation_file = r'NOPP8_20091030_haddock_singles_raven_table_modified.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries removed: 0\n",
      "Integrity test succesfull\n",
      "282 annotations imported.\n"
     ]
    }
   ],
   "source": [
    "annot = load_raven_table(root_dir,audio_dir,annotation_file,deployment_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "print(annot.get_labels_class())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_class                         HK  Total\n",
      "deployment_ID                                \n",
      "USA-NEFSC-SBNMS-200910-NOPP8_CH07  282    282\n",
      "Total                              282    282\n"
     ]
    }
   ],
   "source": [
    "annot.insert_values(label_class= 'HK')\n",
    "annot.insert_values(label_subclass= 'P')\n",
    "print(annot.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xavier.mouy\\Anaconda3\\envs\\ecosound\\lib\\site-packages\\pandas\\core\\arrays\\timedeltas.py:754: RuntimeWarning: invalid value encountered in multiply\n",
      "  return self - (self // other) * other\n"
     ]
    }
   ],
   "source": [
    "annot.to_netcdf(os.path.join(root_dir, 'Annotations_dataset_' + annot.data['deployment_ID'][0] +'_singlepulse_annotations.nc'))\n",
    "#annot.to_raven(root_dir, outfile='Annotations_dataset_' + annot.data['deployment_ID'][0] +'.Table.1.selections.txt', single_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2b: USA-NEFSC-SBNMS-200910-NOPP8_CH07 - pulse train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'C:\\Users\\xavier.mouy\\Documents\\GitHub\\minke-whale-dataset\\datasets\\USA-NEFSC-SBNMS-200910-NOPP8_CH07'\n",
    "audio_dir = r'C:\\Users\\xavier.mouy\\Documents\\GitHub\\minke-whale-dataset\\datasets\\USA-NEFSC-SBNMS-200910-NOPP8_CH07'\n",
    "deployment_file = r'deployment_info.csv' \n",
    "annotation_file = r'NOPP8_20091030_haddock_pulsetrains_concatenated_raven_table_modified.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries removed: 0\n",
      "Integrity test succesfull\n",
      "9446 annotations imported.\n"
     ]
    }
   ],
   "source": [
    "annot = load_raven_table(root_dir,audio_dir,annotation_file,deployment_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "print(annot.get_labels_class())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_class                          HK  Total\n",
      "deployment_ID                                 \n",
      "USA-NEFSC-SBNMS-200910-NOPP8_CH07  9446   9446\n",
      "Total                              9446   9446\n"
     ]
    }
   ],
   "source": [
    "annot.insert_values(label_class= 'HK')\n",
    "annot.insert_values(label_subclass= 'PT')\n",
    "print(annot.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xavier.mouy\\Anaconda3\\envs\\ecosound\\lib\\site-packages\\pandas\\core\\arrays\\timedeltas.py:754: RuntimeWarning: invalid value encountered in multiply\n",
      "  return self - (self // other) * other\n"
     ]
    }
   ],
   "source": [
    "annot.to_netcdf(os.path.join(root_dir, 'Annotations_dataset_' + annot.data['deployment_ID'][0] +'_pulsetrain_annotations.nc'))\n",
    "#annot.to_raven(root_dir, outfile='Annotations_dataset_' + annot.data['deployment_ID'][0] +'.Table.1.selections.txt', single_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
